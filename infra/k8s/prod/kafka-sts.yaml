apiVersion: v1
kind: Service
metadata:
  labels:
    app: kafka
  name: kafka-srv
spec:
  clusterIP: None
  selector:
    app: kafka
  ports:
    - name: tcp-kafka-int
      port: 9092
      protocol: TCP
      targetPort: tcp-kafka-int
    - name: tcp-kafka-ctrl
      port: 29093
      protocol: TCP
      targetPort: tcp-kafka-ctrl
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: kafka
  name: kafka
spec:
  serviceName: kafka-srv
  replicas: 3
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      serviceAccountName: kafka
      containers:
      - name: kafka
        image: docker.io/confluentinc/confluent-local:7.5.0
        imagePullPolicy: IfNotPresent
        command:
        - sh
        - -exc
        - |
          export CLUSTER_ID=$(kafka-storage random-uuid) && \
          export KAFKA_NODE_ID=$(echo ${HOSTNAME##*-}) && \
          export KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://${HOSTNAME}.kafka-srv.default.svc.cluster.local:9092 && \
          export KAFKA_CONTROLLER_QUORUM_VOTERS="0@kafka-0.kafka-srv.default.svc.cluster.local:29093,1@kafka-1.kafka-srv.default.svc.cluster.local:29093,2@kafka-2.kafka-srv.default.svc.cluster.local:29093" && \
          exec /etc/confluent/docker/run
        env:
        - name: KAFKA_LISTENERS
          value: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:29093
        - name: KAFKA_ADVERTISED_LISTENERS
          value: PLAINTEXT://${HOSTNAME}.kafka-srv.default.svc.cluster.local:9092
        - name: KAFKA_CONTROLLER_LISTENER_NAMES
          value: "CONTROLLER"
        - name: KAFKA_LOG_DIRS
          value: "/var/lib/kafka/logs"
        - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
          value: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
        - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
          value: "2"
        - name: KAFKA_DEFAULT_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
          value: "true"
        - name: KAFKA_MIN_INSYNC_REPLICAS
          value: "2"
        - name: KAFKA_LOG_RETENTION_HOURS
          value: "168"
        - name: KAFKA_LOG_SEGMENT_BYTES
          value: "1073741824" # 1GB
        - name: KAFKA_LOG_RETENTION_BYTES
          value: "-1" # Unlimited by size
        ports:
        - containerPort: 9092
          name: tcp-kafka-int
          protocol: TCP
        - containerPort: 29093
          name: tcp-kafka-ctrl
          protocol: TCP
        resources:
          limits:
            cpu: "2" # Maximum of 2 CPU cores
            memory: "2Gi" # Maximum of 3 GiB memory
          requests:
            cpu: "1500m" # 1.5 CPU cores (1500 millicores)
            memory: "2Gi" # 2 GiB memory
        volumeMounts:
        - name: kafka-data
          mountPath: /var/lib/kafka
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext:
        fsGroup: 1000
      terminationGracePeriodSeconds: 30
  volumeClaimTemplates:
  - metadata:
      name: kafka-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
  updateStrategy:
    type: RollingUpdate
